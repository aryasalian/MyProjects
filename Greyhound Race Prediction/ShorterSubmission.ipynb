{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_processing(data):\n",
    "    # Making datetime objects\n",
    "    data.date1 = pd.to_datetime(data.date1)\n",
    "    data.birthdate = pd.to_datetime(data.birthdate)\n",
    "    data.date2 = pd.to_datetime(data.date2)\n",
    "\n",
    "    # Using age as of race date as an input feature\n",
    "    data['age2'] = (data['date2']-data['birthdate']).dt.days\n",
    "    data['season2'] = data['date2'].dt.month.apply(assign_season)\n",
    "\n",
    "# Using season during race as an input feature\n",
    "def assign_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 0        # Winter\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 1        # Spring\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 2        # Summer\n",
    "    else:\n",
    "        return 3        # Fall\n",
    "\n",
    "data = pd.read_csv(\"df.csv\")\n",
    "feature_processing(data)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['stadium_labels'] = label_encoder.fit_transform(data['stadium'])\n",
    "\n",
    "def stadium_labeller(data):\n",
    "    data['stadium_labels'] = label_encoder.transform(data.stadium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Worker function for processing a batch of sentences\n",
    "def get_batch_embeddings(sentences, batch_size=10):\n",
    "    try:\n",
    "        global tokenizer, model\n",
    "        embeddings = []\n",
    "        for i in range(0, len(sentences), batch_size):\n",
    "            batch = sentences[i:i+batch_size]\n",
    "            tokens = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**tokens)\n",
    "            \n",
    "            # Extract embeddings for each [CLS] token\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "# Multithreading function\n",
    "def get_embeddings_multithreading(sentences, chunk_size=100, batch_size=10, num_threads=2):\n",
    "\n",
    "    # Split sentences into chunks\n",
    "    chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]\n",
    "\n",
    "    with tqdm(total=len(chunks), desc=\"Processing Chunks\", unit=\"chunk\") as pbar:\n",
    "        # Process each chunk in parallel\n",
    "        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            futures = {executor.submit(get_batch_embeddings, chunk, batch_size): idx for idx, chunk in enumerate(chunks)}\n",
    "            results = [None] * len(chunks)\n",
    "            for future in as_completed(futures):\n",
    "                idx = futures[future]  # Get the index corresponding to the completed chunk\n",
    "                try:\n",
    "                    result = future.result()  # Retrieve the result of the completed chunk\n",
    "                    results[idx] = result  # Store the result at the correct index\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    print(f\"Chunk at index {idx} generated an exception: {e}\")\n",
    "                \n",
    "    # Flatten the list of results\n",
    "    embeddings = np.vstack(results)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['time2'])\n",
    "Y = data['time2']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Continuous features to be normalized\n",
    "continuous_features = ['time1', 'distance1', 'distance2', 'trap2', 'age2']\n",
    "scaler = StandardScaler()\n",
    "X_train[continuous_features] = scaler.fit_transform(X_train[continuous_features]) # Fits the scaler\n",
    "\n",
    "# Combining all features into a tensor\n",
    "def prepare_features(df):\n",
    "    continuous = df[continuous_features].values\n",
    "    embeddings = np.stack(df['comment_embd'].values)  # Stack embeddings\n",
    "    categorical = df[['stadium_labels', 'season2']].values\n",
    "    return np.hstack([continuous, embeddings, categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/clzbwtq527b2g9qfk2dhk1yr0000gn/T/ipykernel_32255/4242347301.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"greyhound_rnn_model.pth\", map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (rnn): RNN(775, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)  # RNN Layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # Fully Connected Layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passing data through RNN layer\n",
    "        out, hidden = self.rnn(x)  # out: (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Passing last hidden state through the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])  # out: (batch_size, output_size)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "output_size = 1  # Single output\n",
    "input_size = 775  # Number of features\n",
    "\n",
    "loaded_model = RNNModel(input_size=input_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        output_size=output_size,\n",
    "                        num_layers=num_layers)\n",
    "\n",
    "state_dict = torch.load(\"greyhound_rnn_model.pth\", map_location=torch.device('cpu'))\n",
    "loaded_model.load_state_dict(state_dict)\n",
    "\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Chunks: 100%|██████████| 1/1 [00:00<00:00,  4.03chunk/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stadium</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>date1</th>\n",
       "      <th>time1</th>\n",
       "      <th>distance1</th>\n",
       "      <th>trap1</th>\n",
       "      <th>comment1</th>\n",
       "      <th>date2</th>\n",
       "      <th>distance2</th>\n",
       "      <th>trap2</th>\n",
       "      <th>age2</th>\n",
       "      <th>season2</th>\n",
       "      <th>stadium_labels</th>\n",
       "      <th>comment_embd</th>\n",
       "      <th>predtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perry Barr</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>-1.934876</td>\n",
       "      <td>-1.895298</td>\n",
       "      <td>1</td>\n",
       "      <td>slow away, early pace, rails</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>-1.908544</td>\n",
       "      <td>-1.459888</td>\n",
       "      <td>1.475319</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>[-0.7129510641098022, 0.5008367300033569, 0.02...</td>\n",
       "      <td>17.064291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Romford</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>-0.413796</td>\n",
       "      <td>-0.442511</td>\n",
       "      <td>1</td>\n",
       "      <td>slow away, rails, crowded third</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>-0.454554</td>\n",
       "      <td>-1.459888</td>\n",
       "      <td>0.802113</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.8965058922767639, 0.5146982669830322, 0.09...</td>\n",
       "      <td>25.056219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yarmouth</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>2022-09-17</td>\n",
       "      <td>0.286926</td>\n",
       "      <td>0.278072</td>\n",
       "      <td>2</td>\n",
       "      <td>rails to middle, crowded first</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>0.266624</td>\n",
       "      <td>-1.459888</td>\n",
       "      <td>0.714440</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>[-0.6532391309738159, 0.24039848148822784, -0....</td>\n",
       "      <td>28.668789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yarmouth</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>0.247048</td>\n",
       "      <td>0.278072</td>\n",
       "      <td>1</td>\n",
       "      <td>rails, crowded first</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>0.266624</td>\n",
       "      <td>-1.459888</td>\n",
       "      <td>1.475319</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>[-0.685035228729248, 0.39406684041023254, -0.2...</td>\n",
       "      <td>28.541771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henlow</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>-1.868412</td>\n",
       "      <td>-1.872054</td>\n",
       "      <td>5</td>\n",
       "      <td>crowded first</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>-1.885280</td>\n",
       "      <td>0.287593</td>\n",
       "      <td>0.617373</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.42330843210220337, 0.15504837036132812, -0...</td>\n",
       "      <td>17.462933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Romford</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>-0.366322</td>\n",
       "      <td>-0.442511</td>\n",
       "      <td>4</td>\n",
       "      <td>middle to rails, bumped first</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>-0.454554</td>\n",
       "      <td>-0.294901</td>\n",
       "      <td>0.714440</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.8159500956535339, -0.17817294597625732, -0...</td>\n",
       "      <td>25.180483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henlow</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>0.298320</td>\n",
       "      <td>0.254827</td>\n",
       "      <td>2</td>\n",
       "      <td>early pace, crowded second</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>0.243361</td>\n",
       "      <td>0.287593</td>\n",
       "      <td>1.378252</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.5870143175125122, 0.04711996763944626, 0.2...</td>\n",
       "      <td>28.658285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Romford</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>1.796612</td>\n",
       "      <td>1.591392</td>\n",
       "      <td>5</td>\n",
       "      <td>quick away, middle to wide, forced to check fi...</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>-0.454554</td>\n",
       "      <td>0.287593</td>\n",
       "      <td>1.569254</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.8125864267349243, -0.031505037099123, -0.0...</td>\n",
       "      <td>24.939417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harlow</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>-2.202632</td>\n",
       "      <td>-2.325323</td>\n",
       "      <td>2</td>\n",
       "      <td>every chance</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>-2.338925</td>\n",
       "      <td>-0.877394</td>\n",
       "      <td>1.378252</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.42654702067375183, -0.1885596215724945, 0.3...</td>\n",
       "      <td>15.856615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harlow</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>-2.174147</td>\n",
       "      <td>-2.325323</td>\n",
       "      <td>2</td>\n",
       "      <td>slow away, bumped first</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>-0.280076</td>\n",
       "      <td>-1.459888</td>\n",
       "      <td>0.235367</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.9118863344192505, 0.3136812448501587, -0.0...</td>\n",
       "      <td>27.547024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stadium  birthdate      date1     time1  distance1  trap1  \\\n",
       "0  Perry Barr 2018-07-01 2022-09-06 -1.934876  -1.895298      1   \n",
       "1     Romford 2019-02-01 2022-09-22 -0.413796  -0.442511      1   \n",
       "2    Yarmouth 2019-03-01 2022-09-17  0.286926   0.278072      2   \n",
       "3    Yarmouth 2018-07-01 2022-09-21  0.247048   0.278072      1   \n",
       "4      Henlow 2019-04-01 2022-09-25 -1.868412  -1.872054      5   \n",
       "5     Romford 2019-03-01 2022-09-24 -0.366322  -0.442511      4   \n",
       "6      Henlow 2018-08-01 2022-09-24  0.298320   0.254827      2   \n",
       "7     Romford 2018-06-01 2022-09-05  1.796612   1.591392      5   \n",
       "8      Harlow 2018-08-01 2022-09-21 -2.202632  -2.325323      2   \n",
       "9      Harlow 2019-08-01 2022-09-25 -2.174147  -2.325323      2   \n",
       "\n",
       "                                            comment1      date2  distance2  \\\n",
       "0                       slow away, early pace, rails 2022-10-01  -1.908544   \n",
       "1                    slow away, rails, crowded third 2022-10-01  -0.454554   \n",
       "2                     rails to middle, crowded first 2022-10-01   0.266624   \n",
       "3                               rails, crowded first 2022-10-01   0.266624   \n",
       "4                                      crowded first 2022-10-01  -1.885280   \n",
       "5                      middle to rails, bumped first 2022-10-01  -0.454554   \n",
       "6                         early pace, crowded second 2022-10-01   0.243361   \n",
       "7  quick away, middle to wide, forced to check fi... 2022-10-01  -0.454554   \n",
       "8                                       every chance 2022-10-01  -2.338925   \n",
       "9                            slow away, bumped first 2022-10-01  -0.280076   \n",
       "\n",
       "      trap2      age2  season2  stadium_labels  \\\n",
       "0 -1.459888  1.475319        3              12   \n",
       "1 -1.459888  0.802113        3              13   \n",
       "2 -1.459888  0.714440        3              19   \n",
       "3 -1.459888  1.475319        3              19   \n",
       "4  0.287593  0.617373        3               4   \n",
       "5 -0.294901  0.714440        3              13   \n",
       "6  0.287593  1.378252        3               4   \n",
       "7  0.287593  1.569254        3              13   \n",
       "8 -0.877394  1.378252        3               3   \n",
       "9 -1.459888  0.235367        3               3   \n",
       "\n",
       "                                        comment_embd   predtime  \n",
       "0  [-0.7129510641098022, 0.5008367300033569, 0.02...  17.064291  \n",
       "1  [-0.8965058922767639, 0.5146982669830322, 0.09...  25.056219  \n",
       "2  [-0.6532391309738159, 0.24039848148822784, -0....  28.668789  \n",
       "3  [-0.685035228729248, 0.39406684041023254, -0.2...  28.541771  \n",
       "4  [-0.42330843210220337, 0.15504837036132812, -0...  17.462933  \n",
       "5  [-0.8159500956535339, -0.17817294597625732, -0...  25.180483  \n",
       "6  [-0.5870143175125122, 0.04711996763944626, 0.2...  28.658285  \n",
       "7  [-0.8125864267349243, -0.031505037099123, -0.0...  24.939417  \n",
       "8  [0.42654702067375183, -0.1885596215724945, 0.3...  15.856615  \n",
       "9  [-0.9118863344192505, 0.3136812448501587, -0.0...  27.547024  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_data = pd.read_csv(\"unseendf.csv\")\n",
    "feature_processing(unseen_data)\n",
    "stadium_labeller(unseen_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unseen_data['comment1'] = unseen_data['comment1'].astype(str)\n",
    "    sentences = unseen_data['comment1'].tolist()\n",
    "    embeddings = get_embeddings_multithreading(sentences=sentences, chunk_size=500, batch_size=125, num_threads=10)\n",
    "    embeddings_2dlist = embeddings.tolist()\n",
    "    unseen_data['comment_embd'] = embeddings_2dlist\n",
    "\n",
    "unseen_data[continuous_features] = scaler.transform(unseen_data[continuous_features])\n",
    "\n",
    "unseen_tensor = torch.tensor(prepare_features(unseen_data), dtype=torch.float32)\n",
    "print(unseen_tensor.shape[1])\n",
    "\n",
    "unseen_dataset = TensorDataset(unseen_tensor.unsqueeze(1))  # Unsqueeze for seq_length=1\n",
    "test_loader = DataLoader(unseen_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "unseen_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, in test_loader:    # the comma is needed to unpack the single element tuple\n",
    "        predictions = loaded_model(X_batch)\n",
    "        unseen_preds.extend(predictions.numpy())\n",
    "\n",
    "unseen_preds = [unseen_preds[x][0] for x in range(len(unseen_preds))]\n",
    "unseen_data['predtime'] = unseen_preds\n",
    "unseen_data.to_csv(\"~/Downloads/mypred.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
